{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CI7520_Group_Assignment_1_Part_III.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ybu4iAUibPaH",
        "5a-z4VCJYzBr",
        "peyJzuywas-G",
        "8WkGIRm9bKNO",
        "owWOIh8Wbzcd",
        "3pHz6oaugUKW",
        "O1Z2LDRgsi9f",
        "6YIxI1FLuaUV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CI7250 Machine Learning and Artificial Intelligence\n",
        "\n",
        "##Assignment 1\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Group 11 Members:\n",
        "*    Erika Coke - K2112049\n",
        "*    Ladan Saeidi - K2145352\n",
        "*    Çiğdem Şahin - K2058962"
      ],
      "metadata": {
        "id": "5U-vDTVgNsuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**PART III** – Application: Classification (Group Submission)"
      ],
      "metadata": {
        "id": "h-_RW39-YsfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Related Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
        "from time import time\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, balanced_accuracy_score, roc_curve\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.model_selection import KFold, RepeatedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "uONhlYJgZWod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "data =  datasets.load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "-BBEMk3HZ882"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training (80%) and testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "d3I0ZD68aHON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing"
      ],
      "metadata": {
        "id": "Ybu4iAUibPaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Scaling\n",
        "The dataset is unbalanced (i.e.some of the features have values in 1e-2, others are 1e+2), so we will apply feature scaling to ensure the larger features don't overshadown the smaller features when we conduct our testing methods "
      ],
      "metadata": {
        "id": "5a-z4VCJYzBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standardization- StandardScaler "
      ],
      "metadata": {
        "id": "peyJzuywas-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features have a mean of 0 and standard deviation of 1\n",
        "scaler_sd=StandardScaler()\n",
        "#Fit on training set only \n",
        "scaler_sd.fit(X_train)\n",
        "#Apply transform to both the training set and test set \n",
        "X_train_sc=scaler_sd.transform(X_train)\n",
        "X_test_sc=scaler_sd.transform(X_test)"
      ],
      "metadata": {
        "id": "IwnSG2zAasJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalization-MinMax Scaler"
      ],
      "metadata": {
        "id": "8WkGIRm9bKNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_range = MinMaxScaler()\n",
        "#Fit on training set only \n",
        "scaler_range.fit(X_train)\n",
        "#Apply transform to both the training set and test set \n",
        "X_train_mm=scaler_range.transform(X_train)\n",
        "X_test_mm=scaler_range.transform(X_test)\n"
      ],
      "metadata": {
        "id": "Mc9QE28ibNpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA with normalized Data [1]\n"
      ],
      "metadata": {
        "id": "owWOIh8Wbzcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 99% of variance\n",
        "#Make an instance of the Model\n",
        "# use thisnumber for plotting\n",
        "pca1=PCA(.99)\n",
        "pca1.fit(X_train_sc)\n",
        "print( \"the number of components: \",pca1.n_components_ )\n",
        "\n",
        "pca2=PCA(.95)\n",
        "pca2.fit(X_train_sc)\n",
        "print( \"the number of components: \",pca2.n_components_ )\n",
        "##################PCA with min_max scaling\n",
        "# 99% of variance\n",
        "#Make an instance of the Model\n",
        "pca_mm=PCA(.99)\n",
        "pca_mm.fit(X_train_mm)\n",
        "print( \"the number of components: \",pca_mm.n_components_ )\n",
        "\n",
        "# use this instance through the code\n",
        "pca = PCA(0.99)\n",
        "df_train_pca = pca.fit_transform(X_train_sc)\n",
        "# Apply PCA model to the test data\n",
        "df_test_pca = pca.transform(X_test_sc)\n",
        "# pca with min_max scaling\n",
        "X_train_mm_pca= pca_mm.transform(X_train_mm)\n",
        "X_test_mm_pca= pca_mm.transform(X_test_mm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N34kO9j_c_GY",
        "outputId": "342ff672-88f9-4082-d827-a22fd6a23222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the number of components:  17\n",
            "the number of components:  10\n",
            "the number of components:  16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the PCA[2]"
      ],
      "metadata": {
        "id": "3pHz6oaugUKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_without_std = pca.explained_variance_ratio_\n",
        "#Cumulative sum of pca explained variance greater than 1\n",
        "# PCA with data standardization\n",
        "pca_with_std = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
        "features1=range(pca1.n_components_)\n",
        "features2=range(pca2.n_components_)\n",
        "features3=range(pca_mm.n_components_)\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.bar(features1,pca1.explained_variance_ratio_,color=\"blue\")  \n",
        "plt.xticks(features1)\n",
        "plt.xlabel(\"PCA features\")\n",
        "plt.ylabel(\"variance 99%\")\n",
        "plt.subplot(122)\n",
        "plt.bar(features2,pca2.explained_variance_ratio_,color=\"Orange\")\n",
        "plt.xticks(features2)\n",
        "plt.xlabel(\"PCA features\")\n",
        "plt.ylabel(\"variance 95%\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "mHDo_EghgRaj",
        "outputId": "44eab851-dfb2-469d-c04e-5c7d5dc5974f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Logistic Regression Algorithm**[3] "
      ],
      "metadata": {
        "id": "yqw_bkLkhCml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logisticRegr = LogisticRegression(solver = 'lbfgs',random_state =42)\n",
        "logisticRegr.fit(X_train, y_train)\n",
        "predictions_lr = logisticRegr.predict(X_test)\n",
        "acc1_lr = accuracy_score(y_test,predictions_lr)*100\n",
        "t1_lr = time()\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_lr))\n",
        "print('\\nClassification Report: \\n',classification_report(y_test,predictions_lr))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_lr),2))\n",
        "print(\"Accuracy: \", round(metrics.accuracy_score(y_test, predictions_lr),2))\n",
        "y_pred_proba_1 = logisticRegr.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC: \", round(roc_auc_score(y_test, y_pred_proba_1),2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAPL4kWdoVaD",
        "outputId": "d3de6fe1-ca6e-4034-ae58-490e9cbc1a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[45  2]\n",
            " [ 4 63]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94        47\n",
            "           1       0.97      0.94      0.95        67\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.94      0.95      0.95       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "Balance Accuracy:  0.95\n",
            "Accuracy:  0.95\n",
            "ROC AUC:  0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv = RepeatedKFold(n_splits=10)\n",
        "logisticRegr_score1 = cross_val_score(logisticRegr, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score1), np.std(logisticRegr_score1)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYVlzUcZod11",
        "outputId": "8554ef8c-641e-46ab-c3ae-9d6e5ba99c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation score: 94.38% (+/- 3.77%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Algorithm with PCA"
      ],
      "metadata": {
        "id": "of85Kg8wrKj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# default solver is incredibly slow which is why it was changed to 'lbfgs'\n",
        "logisticRegr = LogisticRegression(solver = 'lbfgs',random_state =42)\n",
        "logisticRegr.fit(df_train_pca, y_train)\n",
        "predictions_lr = logisticRegr.predict(df_test_pca)\n",
        "acc2_lr = accuracy_score(y_test,predictions_lr)*100\n",
        "t2_lr = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_lr))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_lr))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_lr),2))\n",
        "y_pred_proba_2 = logisticRegr.predict_proba(df_test_pca)[:, 1]\n",
        "print(\"ROC AUC: \", round(roc_auc_score(y_test, y_pred_proba_2),2))\n",
        "cv = RepeatedKFold(n_splits=10)\n",
        "logisticRegr_score2 = cross_val_score(logisticRegr, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score2), np.std(logisticRegr_score2)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD3_UjHurTgv",
        "outputId": "6ef4057f-cb28-4c1d-b521-6a633e1983c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[45  2]\n",
            " [ 2 65]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        47\n",
            "           1       0.97      0.97      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Balance Accuracy:  0.96\n",
            "ROC AUC:  0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation score: 94.38% (+/- 3.77%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression Algorithm with scaling data\n"
      ],
      "metadata": {
        "id": "O1Z2LDRgsi9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logisticRegr = LogisticRegression(solver = 'lbfgs',random_state =42)\n",
        "logisticRegr.fit(X_train_sc, y_train)\n",
        "predictions_lr = logisticRegr.predict(X_test_sc)\n",
        "acc3_lr = accuracy_score(y_test,predictions_lr)*100\n",
        "t3_lr = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_lr))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_lr))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_lr),2))\n",
        "y_pred_proba_3 = logisticRegr.predict_proba(X_test_sc)[:, 1]\n",
        "print(\"ROC AUC: \", round(roc_auc_score(y_test, y_pred_proba_3),2))\n",
        "\n",
        "logisticRegr_score3 = cross_val_score(logisticRegr, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score3), np.std(logisticRegr_score3)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvLBP8v8rTfX",
        "outputId": "afb09a47-fd62-4e15-ad9a-a910d1270a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[45  2]\n",
            " [ 2 65]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        47\n",
            "           1       0.97      0.97      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Balance Accuracy:  0.96\n",
            "ROC AUC:  0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation score: 94.38% (+/- 3.77%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression Algorithm using min_max scaling\n"
      ],
      "metadata": {
        "id": "6YIxI1FLuaUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logisticRegr = LogisticRegression(solver = 'lbfgs',random_state =42)\n",
        "logisticRegr.fit(X_train_mm, y_train)\n",
        "predictions_lr = logisticRegr.predict(X_test_mm)\n",
        "acc4_lr = accuracy_score(y_test,predictions_lr)*100\n",
        "t4_lr = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_lr))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_lr))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_lr),2))\n",
        "y_pred_proba_4 = logisticRegr.predict_proba(X_test_mm)[:, 1]\n",
        "print(\"ROC AUC: \", round(roc_auc_score(y_test, y_pred_proba_4),2))\n",
        "\n",
        "logisticRegr_score4 = cross_val_score(logisticRegr, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score4), np.std(logisticRegr_score4)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsSUxwEotbUi",
        "outputId": "00ba73a8-845e-4690-f51c-9ab0ce245511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[43  4]\n",
            " [ 0 67]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.96        47\n",
            "           1       0.94      1.00      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "Balance Accuracy:  0.96\n",
            "ROC AUC:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation score: 94.38% (+/- 3.77%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression using Min_Max PCA"
      ],
      "metadata": {
        "id": "THCD73uNB-Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logisticRegr = LogisticRegression(solver = 'lbfgs',random_state =42)\n",
        "logisticRegr.fit(X_train_mm_pca, y_train)\n",
        "predictions_lr = logisticRegr.predict(X_test_mm_pca)\n",
        "acc5_lr = accuracy_score(y_test,predictions_lr)*100\n",
        "t5_lr = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_lr))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_lr))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_lr),2))\n",
        "y_pred_proba_5 = logisticRegr.predict_proba(X_test_mm_pca)[:, 1]\n",
        "print(\"ROC AUC: \", round(roc_auc_score(y_test, y_pred_proba_5),2))\n",
        "\n",
        "logisticRegr_score5 = cross_val_score(logisticRegr, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score5), np.std(logisticRegr_score5)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si2dfNsCCBSD",
        "outputId": "8d1fb5e7-8622-4e1e-9016-50259217abfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[43  4]\n",
            " [ 0 67]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.96        47\n",
            "           1       0.94      1.00      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "Balance Accuracy:  0.96\n",
            "ROC AUC:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation score: 94.38% (+/- 3.77%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression **using GridSearchCV**\n"
      ],
      "metadata": {
        "id": "bNdehpCs1uE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will using GridSearchCV for Logistic Regression to find the best hyperparameters\n",
        "# This code was modified from the sample code at the following source \n",
        "#/***************************************************************************************\n",
        "#   *    Title: CHyperparameter Optimization With Random Search and Grid Search\n",
        "#   *    Author: Jason Brownlee\n",
        "#   *    Date: September 14, 2020\n",
        "#   *    Availability: https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/[4]\n",
        "#   *\n",
        "#***************************************************************************************/\n",
        "# grid search logistic regression model \n",
        "# define model\n",
        "# if we use scaled X the number of FN increase\n",
        "model = LogisticRegression()\n",
        "# define evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define search space\n",
        "space = dict()\n",
        "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
        "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
        "# space['C'] = np.logspace(-4, 4, 50)\n",
        "# define search\n",
        "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
        "# execute search\n",
        "result = search.fit(X_train_sc,y_train)\n",
        "t6_lr = time()\n",
        "# summarize result\n",
        "print('Best Score: %s' % result.best_score_*100)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8Yht3qJ4lR5",
        "outputId": "a0ee2980-01a9-40a7-e3f1-ee4ec1d1cc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385Best Score: 0.9802254428341385\n",
            "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "1440 fits failed out of a total of 2880.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "240 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 459, in _check_solver\n",
            "    solver\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.95164251 0.95093398        nan        nan        nan 0.36256039\n",
            " 0.63743961 0.63743961 0.94059581        nan        nan        nan\n",
            " 0.95164251 0.95093398        nan        nan        nan 0.36256039\n",
            " 0.64334944 0.64334944 0.94206119        nan        nan        nan\n",
            " 0.95164251 0.95093398        nan        nan        nan 0.36256039\n",
            " 0.88808374 0.88808374 0.95231884        nan        nan        nan\n",
            " 0.95164251 0.95093398        nan        nan        nan 0.91943639\n",
            " 0.95172303 0.95172303 0.97064412        nan        nan        nan\n",
            " 0.95164251 0.95093398        nan        nan        nan 0.96624799\n",
            " 0.97512077 0.97512077 0.98022544        nan        nan        nan\n",
            " 0.95164251 0.95093398        nan        nan        nan 0.97365539\n",
            " 0.97876006 0.97876006 0.98020934        nan        nan        nan\n",
            " 0.95164251 0.95093398        nan        nan        nan 0.9662963\n",
            " 0.96853462 0.96853462 0.96853462        nan        nan        nan\n",
            " 0.95164251 0.95093398        nan        nan        nan 0.9531401\n",
            " 0.96191626 0.96191626 0.96191626        nan        nan        nan]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on test data \n",
        "grid_predictions = search.predict(X_test_sc) \n",
        "\n",
        "# test_accuracy=accuracy_score(y_test,grid_predictions)*100\n",
        "# print(\"Accuracy for our testing dataset with tuning is : {:.2f}%\".format(test_accuracy) )\n",
        "acc6_lr = accuracy_score(y_test, grid_predictions)*100\n",
        "# t5_lr = time()\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test,  grid_predictions))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test, grid_predictions))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test,  grid_predictions),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test,  grid_predictions),2))\n",
        "y_pred = search.predict_proba(X_test_sc)[:, 1]\n",
        "print(\"ROC AUC: \", round(roc_auc_score(y_test, y_pred),2))\n",
        "logisticRegr_score6 = cross_val_score(logisticRegr, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score6), np.std(logisticRegr_score6)*2))"
      ],
      "metadata": {
        "id": "r-8EqC59898O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0d53ea-ee81-4ce5-b287-9550550de92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[44  3]\n",
            " [ 1 66]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        47\n",
            "           1       0.96      0.99      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "Balance Accuracy:  0.96\n",
            "Accuracy :  0.96\n",
            "ROC AUC:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation score: 94.38% (+/- 3.77%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison for Logistic Regression Algorithm"
      ],
      "metadata": {
        "id": "NubeMD7BvS-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The results for Logistic Regression are  :                      time = {} ,   Accuracy = {} .\".format(t1_lr, acc1_lr))\n",
        "print(\"The results for Logistic Regression using PCA are  :            time = {} ,  Accuracy = {} .\".format(t2_lr, acc2_lr))\n",
        "print(\"The results for Logistic Regression using scaling are  :        time = {} ,  Accuracy = {} .\".format(t3_lr, acc3_lr))\n",
        "print(\"The results for Logistic Regression using Min_max Scaler are  : time = {} ,   Accuracy = {} .\".format(t4_lr, acc4_lr))\n",
        "print(\"The results for Logistic Regression using PCA Min_max  are  :   time = {} ,   Accuracy = {} .\".format(t5_lr, acc5_lr))\n",
        "print(\"\\nThe results for Logistic Regression using GridSearchCV are  :   time = {} ,  Accuracy = {} .\".format(t6_lr, acc6_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68CLkhajvUFP",
        "outputId": "3788750c-77f8-40d5-bc80-6741920af0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The results for Logistic Regression are  :                      time = 1645543172.4205518 ,   Accuracy = 94.73684210526315 .\n",
            "The results for Logistic Regression using PCA are  :            time = 1645543173.0152287 ,  Accuracy = 96.49122807017544 .\n",
            "The results for Logistic Regression using scaling are  :        time = 1645543173.9203353 ,  Accuracy = 96.49122807017544 .\n",
            "The results for Logistic Regression using Min_max Scaler are  : time = 1645543174.4750674 ,   Accuracy = 96.49122807017544 .\n",
            "The results for Logistic Regression using PCA Min_max  are  :   time = 1645543175.658889 ,   Accuracy = 96.49122807017544 .\n",
            "\n",
            "The results for Logistic Regression using GridSearchCV are  :   time = 1645543220.9863284 ,  Accuracy = 96.49122807017544 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of Cross validation scores"
      ],
      "metadata": {
        "id": "TafNTC8EGoUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross validation score Logistic Regression :                      {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score1), np.std(logisticRegr_score1)*2))\n",
        "print(\"Cross validation score Logistic Regression using PCA:             {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score2), np.std(logisticRegr_score2)*2))\n",
        "print(\"Cross validation score Logistic Regression using scaling:         {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score3), np.std(logisticRegr_score3)*2))\n",
        "print(\"Cross validation score Logistic Regression using Min_max Scaler:  {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score4), np.std(logisticRegr_score4)*2))\n",
        "print(\"Cross validation score Logistic Regression using PCA Min_max:     {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score5), np.std(logisticRegr_score5)*2))\n",
        "print(\"Cross validation score Logistic Regression using GridSearchCV:    {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score6), np.std(logisticRegr_score6)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKsxrVlWGsce",
        "outputId": "e5f86b69-f01e-4a8d-df3e-31afdf2ca6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation score Logistic Regression :                      94.38% (+/- 3.77%)\n",
            "Cross validation score Logistic Regression using PCA:             94.38% (+/- 3.77%)\n",
            "Cross validation score Logistic Regression using scaling:         94.38% (+/- 3.77%)\n",
            "Cross validation score Logistic Regression using Min_max Scaler:  94.38% (+/- 3.77%)\n",
            "Cross validation score Logistic Regression using PCA Min_max:     94.38% (+/- 3.77%)\n",
            "Cross validation score Logistic Regression using GridSearchCV:    94.38% (+/- 3.77%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Support Vector Machines**[5]\n",
        "Kernel = Linear\n",
        "* Note: except ROC AUC Score standard scaling gave the best accuracy.\n",
        "* Note: compare to Cross Validation score kernel=\"linear\" is better\n",
        "\n"
      ],
      "metadata": {
        "id": "F6TV_ikPxiun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='linear', probability=True)\n",
        "model_svm.fit(X_train, y_train)\n",
        "\n",
        "predictions_svm = model_svm.predict(X_test)\n",
        "acc1_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t1_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \",  round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_1 = model_svm.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_1),2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5Q25-KSxsAf",
        "outputId": "21bea5ab-685b-43b3-9b18-4c79f910a478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[46  1]\n",
            " [ 4 63]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95        47\n",
            "           1       0.98      0.94      0.96        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.95      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Balance Accuracy:  0.96\n",
            "Accuracy :  0.96\n",
            "ROC AUC : 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_score1 = cross_val_score(model_svm, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score1), np.std(svm_score1)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2JMSGIqXuF0",
        "outputId": "9502f96f-1f9c-4779-c59e-d9fd4e24de69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation score: 95.43% (+/- 3.90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM: Changing the number of C and gamma"
      ],
      "metadata": {
        "id": "o9ytoqlrzQL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='linear', C=10, gamma=10,random_state=1, probability=True)\n",
        "model_svm.fit(X_train, y_train)\n",
        "\n",
        "predictions_svm = model_svm.predict(X_test)\n",
        "acc2_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t2_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_2 = model_svm.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_2),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKy77FemzTCi",
        "outputId": "6c398506-5120-4585-c672-392112401082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[46  1]\n",
            " [ 3 64]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96        47\n",
            "           1       0.98      0.96      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.97      0.96       114\n",
            "weighted avg       0.97      0.96      0.97       114\n",
            "\n",
            "Balance Accuracy:  0.97\n",
            "ROC AUC : 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score2 = cross_val_score(model_svm, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score2), np.std(svm_score2)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXk47jidbSeJ",
        "outputId": "f1c28aad-2894-4a86-f90b-3f69934ddde2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation score: 95.08% (+/- 4.37%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM using PCA"
      ],
      "metadata": {
        "id": "uWLYhqd-z9DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='linear',random_state=1, probability=True)\n",
        "model_svm.fit(df_train_pca, y_train)\n",
        "predictions_svm = model_svm.predict(df_test_pca)\n",
        "acc3_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t3_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \",  round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_3 = model_svm.predict_proba(df_test_pca)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_3),2))\n",
        "# cv = RepeatedKFold(n_splits=10)\n",
        "svm_score3 = cross_val_score(model_svm, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score3), np.std(svm_score3)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mdRlCKtz-dE",
        "outputId": "a5656afb-2da7-4905-c05a-7419dd3fb3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[45  2]\n",
            " [ 2 65]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        47\n",
            "           1       0.97      0.97      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Balance Accuracy:  0.96\n",
            "Accuracy :  0.96\n",
            "ROC AUC : 1.0\n",
            "Cross validation score: 95.43% (+/- 3.90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM using Scaling data"
      ],
      "metadata": {
        "id": "kIRV3d_RWihT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='linear', C=1, gamma=1,random_state=1, probability=True)\n",
        "model_svm.fit(X_train_sc, y_train)\n",
        "predictions_svm = model_svm.predict(X_test_sc)\n",
        "acc4_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t4_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n',classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \",  round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_4 = model_svm.predict_proba(X_test_sc)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_4),2))\n",
        "\n",
        "# cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score4 = cross_val_score(model_svm, X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score4), np.std(svm_score4)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3dww7TVz-fL",
        "outputId": "919b92f8-618c-414c-81e5-0588b03d91cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[46  1]\n",
            " [ 1 66]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        47\n",
            "           1       0.99      0.99      0.99        67\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.98      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "Balance Accuracy:  0.98\n",
            "Accuracy :  0.98\n",
            "ROC AUC : 1.0\n",
            "Cross validation score: 95.43% (+/- 3.90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM with MinMax scaling"
      ],
      "metadata": {
        "id": "yqlw-kD3YEFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='linear', C=1, gamma=1,random_state=1, probability=True)\n",
        "model_svm.fit(X_train_mm, y_train)\n",
        "predictions_svm = model_svm.predict(X_test_mm)\n",
        "acc5_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t5_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n',classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_5 = model_svm.predict_proba(X_test_mm)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_5),2))\n",
        "# cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score5 = cross_val_score(model_svm,  X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score5), np.std(svm_score5)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1pU9bbjXpBo",
        "outputId": "19393d07-c95e-4e3a-e881-7b98ab7ca30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[44  3]\n",
            " [ 1 66]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        47\n",
            "           1       0.96      0.99      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "Balance Accuracy:  0.96\n",
            "Accuracy :  0.96\n",
            "ROC AUC : 1.0\n",
            "Cross validation score: 95.43% (+/- 3.90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM using Min_Max PCA"
      ],
      "metadata": {
        "id": "P3i3sVHy_jpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='linear', probability=True)\n",
        "model_svm.fit(X_train_mm_pca, y_train)\n",
        "predictions_svm = model_svm.predict(X_test_mm_pca)\n",
        "acc6_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t6_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n',classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_6 = model_svm.predict_proba(X_test_mm_pca)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_6),2))\n",
        "# cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score6 = cross_val_score(model_svm,  X, y, cv=10, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score6), np.std(svm_score6)*2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSr_v5v7_l_D",
        "outputId": "137fc4ae-b4f9-4656-cf64-99e638bf0921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[44  3]\n",
            " [ 1 66]]\n",
            "\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96        47\n",
            "           1       0.96      0.99      0.97        67\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "Balance Accuracy:  0.96\n",
            "Accuracy :  0.96\n",
            "ROC AUC : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Support Vector Machines**\n",
        "Kernel = rbf"
      ],
      "metadata": {
        "id": "yEkwxtpBZ2af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='rbf', probability=True)\n",
        "model_svm.fit(X_train, y_train)\n",
        "\n",
        "predictions_svm = model_svm.predict(X_test)\n",
        "acc7_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t7_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \",  round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_7 = model_svm.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_7),2))\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score7 = cross_val_score(model_svm, X, y, cv=cv, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score7), np.std(svm_score7)*2))"
      ],
      "metadata": {
        "id": "J97PQn4UZ3zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM: Changing the number of C and gamma"
      ],
      "metadata": {
        "id": "oWo7OmOWaU72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='rbf',C=10, gamma=10, probability=True)\n",
        "model_svm.fit(X_train, y_train)\n",
        "\n",
        "predictions_svm = model_svm.predict(X_test)\n",
        "acc8_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t8_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_8 = model_svm.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_8),2))\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score8 = cross_val_score(model_svm, X, y, cv=cv, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score8), np.std(svm_score8)*2))"
      ],
      "metadata": {
        "id": "6ELsOnyUaV-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM using PCA"
      ],
      "metadata": {
        "id": "uEYeQ3kuam14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='rbf',  probability=True)\n",
        "model_svm.fit(df_train_pca, y_train)\n",
        "predictions_svm = model_svm.predict(df_test_pca)\n",
        "acc9_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t9_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \",  round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_9 = model_svm.predict_proba(df_test_pca)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_9),2))\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score9 = cross_val_score(model_svm, X, y, cv=cv, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score9), np.std(svm_score9)*2))"
      ],
      "metadata": {
        "id": "cHe8L5W3arjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM using Scaling data"
      ],
      "metadata": {
        "id": "2ByZN4J5a4uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='rbf', probability=True)\n",
        "model_svm.fit(X_train_sc, y_train)\n",
        "predictions_svm = model_svm.predict(X_test_sc)\n",
        "acc10_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t10_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \",  round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_10 = model_svm.predict_proba(X_test_sc)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_10),2))\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score10 = cross_val_score(model_svm, X, y, cv=cv, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score10), np.std(svm_score10)*2))"
      ],
      "metadata": {
        "id": "B871Xh06a-nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM with MinMax scaling"
      ],
      "metadata": {
        "id": "oefx0lK5a4rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='rbf',random_state=1, probability=True)\n",
        "model_svm.fit(X_train_mm, y_train)\n",
        "predictions_svm = model_svm.predict(X_test_mm)\n",
        "acc11_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t11_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_11 = model_svm.predict_proba(X_test_mm)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_11),2))\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score11 = cross_val_score(model_svm, X, y, cv=cv, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score11), np.std(svm_score11)*2))"
      ],
      "metadata": {
        "id": "NDgpAl6xbLiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM using Min_Max PCA"
      ],
      "metadata": {
        "id": "d6KZD2fwAj9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='rbf', probability=True)\n",
        "model_svm.fit(X_train_mm_pca, y_train)\n",
        "predictions_svm = model_svm.predict(X_test_mm_pca)\n",
        "acc12_svm = accuracy_score(y_test, predictions_svm)*100\n",
        "t12_svm = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_svm))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_svm))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_svm),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_svm),2))\n",
        "y_pred_proba_svm_12 = model_svm.predict_proba(X_test_mm_pca)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_svm_12),2))\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "svm_score12 = cross_val_score(model_svm, X,y, cv=cv, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score12), np.std(svm_score12)*2))"
      ],
      "metadata": {
        "id": "HiNSmJ8hAjDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM **using GridSearchCV**"
      ],
      "metadata": {
        "id": "IUYb0oHBiI5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will using GridSearchCV for SVM to find the best hyperparameters\n",
        "# This code was modified from the sample code at the following source \n",
        "#/***************************************************************************************\n",
        "#   *    Title: Hyperparameter Tuning with Sklearn GridSearchCV and RandomizedSearchCV\n",
        "#   *    Author: Veer Kumar\n",
        "#   *    Date: October 5, 2021\n",
        "#   *    Availability: https://machinelearningknowledge.ai/hyperparameter-tuning-with-sklearn-gridsearchcv-and-randomizedsearchcv/[6]\n",
        "#   *\n",
        "#***************************************************************************************/\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100],\n",
        "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "\t\t\t'kernel': ['rbf','linear']}\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# import seaborn as sns\n",
        "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=4)\n",
        "grid.fit(X_train_sc,y_train)\n",
        "t13_svm = time()\n",
        "grid_predictions = grid.predict(X_test_sc)\n",
        "# cm = confusion_matrix(y_test, grid_predictions)\n",
        "# sns.heatmap(cm, annot=True)\n",
        "# print(classification_report(y_test,grid_predictions))\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "metadata": {
        "id": "P2cn9W0ziC1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc13_svm = accuracy_score(y_test, grid_predictions)*100\n",
        "# t11_svm = time()\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test,  grid_predictions))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test, grid_predictions))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test,  grid_predictions),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test,  grid_predictions),2))\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10)\n",
        "svm_score13 = cross_val_score(model_svm, X, y, cv=cv, scoring='accuracy')\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score13), np.std(svm_score13)*2))"
      ],
      "metadata": {
        "id": "gwHLEsOMtexu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison for SVM using linear as Kernel & rbf"
      ],
      "metadata": {
        "id": "2nr9JX-ZbWwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SVM with Kernel = linear :\")\n",
        "print(\"The results for SVM are  :                          time = {} ,  Accuracy = {} .\".format(t1_svm, acc1_svm))\n",
        "print(\"The results for SVM changing C & gamma  :           time = {} , Accuracy = {} .\".format(t2_svm, acc2_svm))\n",
        "print(\"The results for SVM using PCA are  :                time = {} , Accuracy = {} .\".format(t3_svm, acc3_svm))\n",
        "print(\"The results for SVM using standard scaling are  :   time = {} ,  Accuracy = {} .\".format(t4_svm, acc4_svm))\n",
        "print(\"The results for SVM using Min_Max Scaling are  :    time = {} ,  Accuracy = {} .\".format(t5_svm, acc5_svm))\n",
        "print(\"The results for SVM using PCA Min_Max are  :        time = {} ,  Accuracy = {} .\".format(t6_svm, acc6_svm))\n",
        "print(\"SVM with Kernel = rbf :\")\n",
        "print(\"The results for SVM are  :                          time = {} ,  Accuracy = {} .\".format(t7_svm, acc7_svm))\n",
        "print(\"The results for SVM changing C & gamma  :           time = {} , Accuracy = {} .\".format(t8_svm, acc8_svm))\n",
        "print(\"The results for SVM using PCA are  :                time = {} , Accuracy = {} .\".format(t9_svm, acc9_svm))\n",
        "print(\"The results for SVM using standard scaling are  :   time = {} ,  Accuracy = {} .\".format(t10_svm, acc10_svm))\n",
        "print(\"The results for SVM using Min_Max Scaling are  :    time = {} ,  Accuracy = {} .\".format(t11_svm, acc11_svm))\n",
        "print(\"The results for SVM using PCA Min_Max are  :        time = {} ,  Accuracy = {} .\".format(t12_svm, acc12_svm))\n",
        "print(\"\\nThe results for SVM using GridSearchCV are  :       time = {} ,  Accuracy = {} .\".format(t13_svm, acc13_svm))"
      ],
      "metadata": {
        "id": "wmaXiz-EbX7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison of cross validation scores"
      ],
      "metadata": {
        "id": "-5CWWXRrN3ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross validation score SVM with Kernel = linear :\")\n",
        "print(\"Cross validation score SVM are  :                                 {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score1), np.std(svm_score1)*2))\n",
        "print(\"Cross validation score changing C & gamma  :                      {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score2), np.std(svm_score2)*2))\n",
        "print(\"Cross validation score SVM using PCA are  :                       {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score3), np.std(svm_score3)*2))\n",
        "print(\"Cross validation score SVM using standard scaling are  :          {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score4), np.std(svm_score4)*2))\n",
        "print(\"Cross validation score SVM using Min_Max Scaling are  :           {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score5), np.std(svm_score5)*2))\n",
        "print(\"Cross validation score SVM using PCA Min_Max are  :               {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score6), np.std(svm_score6)*2))\n",
        "print(\"Cross validation score SVM with Kernel = rbf :\")\n",
        "print(\"Cross validation score SVM are  :                                 {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score7), np.std(svm_score7)*2))\n",
        "print(\"Cross validation score SVM changing C & gamma  :                  {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score8), np.std(svm_score8)*2))\n",
        "print(\"Cross validation score SVM using PCA are  :                       {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score9), np.std(svm_score9)*2))\n",
        "print(\"Cross validation score SVM using standard scaling are  :          {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score10), np.std(svm_score10)*2))\n",
        "print(\"Cross validation score SVM using Min_Max Scaling are  :           {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score11), np.std(svm_score11)*2))\n",
        "print(\"Cross validation score SVM using PCA Min_Max are  :               {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score12), np.std(svm_score12)*2))\n",
        "print(\"\\nCross validation score SVM using GridSearchCV are  :              {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score13), np.std(svm_score13)*2))"
      ],
      "metadata": {
        "id": "XvCBIBOlN7HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting SVM[7]\n"
      ],
      "metadata": {
        "id": "xP3QWohQe8YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mesh to plot in (just with first two features)\n",
        "X = data.data[:,:2] # we only take the first two features\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "h = (x_max / x_min)/100\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "np.arange(y_min, y_max, h))\n",
        "\n",
        "svc = svm.SVC(kernel='rbf', C=1,gamma=1).fit(X, y)\n",
        "plt.subplot(1, 2, 1)\n",
        " \n",
        "Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
        "plt.xlabel('mean radius')\n",
        "plt.ylabel('mean texture')\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.title('SVM with rbf kernel')\n",
        "\n",
        "svc = svm.SVC(kernel='linear', C=1,gamma=1).fit(X, y)\n",
        "plt.subplot(1, 2, 2)\n",
        " \n",
        "Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
        "plt.xlabel('mean radius')\n",
        "plt.ylabel('mean texture')\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.title('SVM with linear kernel')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wjSTjb2Fe-I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**K- Nearest Neighbor(KNN)**[8][9][10]\n"
      ],
      "metadata": {
        "id": "GaIgbOZIfLFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the best number for K"
      ],
      "metadata": {
        "id": "WzQqVS5KgFkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the best number for K, the 10th number in the array is the lowest error and give us the higher accuracy, so K=10 is the best\n",
        "list_of_errors = []\n",
        "for i in range(1,20):\n",
        "  knn = KNeighborsClassifier(n_neighbors=i)\n",
        "  knn.fit(X_train,y_train)\n",
        "  pred_i = knn.predict(X_test)\n",
        "  list_of_errors.append(np.mean(pred_i != y_test))\n",
        "print(list_of_errors)"
      ],
      "metadata": {
        "id": "IbJ9iUpffNtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with k under 10 the results were not good\n",
        "knn = KNeighborsClassifier(n_neighbors=10,metric = 'minkowski', p = 2)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions_knn = knn.predict(X_test)\n",
        "t1_knn = time()\n",
        "acc1_knn = accuracy_score(y_test,predictions_knn)*100\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_knn))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_knn))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_knn),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_knn),2))\n",
        "y_pred_proba_knn_1 = knn.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_knn_1),2))\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "k_score1 = cross_val_score(knn, X, y, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score1), np.std(k_score1)*2))"
      ],
      "metadata": {
        "id": "w4GIHd7LgPnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN using standard Scaling"
      ],
      "metadata": {
        "id": "gVtGih3ikfWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=10,metric = 'minkowski', p = 2)\n",
        "knn.fit(X_train_sc, y_train)\n",
        "predictions_knn = knn.predict(X_test_sc)\n",
        "acc2_knn = accuracy_score(y_test,predictions_knn)*100\n",
        "t2_knn = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_knn))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_knn))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_knn),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_knn),2))\n",
        "y_pred_proba_knn_2 = knn.predict_proba(X_test_sc)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_knn_2),2))\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "k_score2 = cross_val_score(knn, X, y, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score2), np.std(k_score2)*2))"
      ],
      "metadata": {
        "id": "WfLD5yWThNiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN using PCA"
      ],
      "metadata": {
        "id": "HvdMBDbflpKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=10,metric = 'minkowski', p = 2)\n",
        "knn.fit(df_train_pca, y_train)\n",
        "predictions_knn = knn.predict(df_test_pca)\n",
        "acc3_knn = accuracy_score(y_test,predictions_knn)*100\n",
        "t3_knn = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_knn))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_knn))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_knn),2))\n",
        "y_pred_proba_knn_3 = knn.predict_proba(df_test_pca)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_knn_3),2))\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "k_score3 = cross_val_score(knn, X, y, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score3), np.std(k_score3)*2))"
      ],
      "metadata": {
        "id": "5aTOpkvIlVKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN with MinMax scaling"
      ],
      "metadata": {
        "id": "9rD_lLOhmJPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train_mm, y_train)\n",
        "predictions_knn = knn.predict(X_test_mm)\n",
        "acc4_knn = accuracy_score(y_test,predictions_knn)*100\n",
        "t4_knn = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_knn))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_knn))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_knn),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_knn),2))\n",
        "y_pred_proba_knn_4 = knn.predict_proba(X_test_mm)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_knn_4),2))\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "k_score4 = cross_val_score(knn, X, y, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score4), np.std(k_score4)*2))"
      ],
      "metadata": {
        "id": "ofhaFsknmKLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN using Min_Max PCA"
      ],
      "metadata": {
        "id": "4Y6ejk7995kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train_mm_pca, y_train)\n",
        "predictions_knn = knn.predict(X_test_mm_pca)\n",
        "acc5_knn = accuracy_score(y_test,predictions_knn)*100\n",
        "t5_knn = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_knn))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_knn))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_knn),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_knn),2))\n",
        "y_pred_proba_knn_5 = knn.predict_proba(X_test_mm_pca)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_knn_5),2))\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "k_score5 = cross_val_score(knn, X, y , cv=cv, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score5), np.std(k_score5)*2))"
      ],
      "metadata": {
        "id": "dePyQGRL9_r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN **using GridSearchCV**"
      ],
      "metadata": {
        "id": "U89BYzfUFODi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will using GridSearchCV for SVM to find the best hyperparameters\n",
        "# This code was modified from the sample code at the following source \n",
        "#/***************************************************************************************\n",
        "#   *    Title: Hyperparameter Tuning with Sklearn GridSearchCV and RandomizedSearchCV\n",
        "#   *    Author: Veer Kumar\n",
        "#   *    Date: October 5, 2021\n",
        "#   *    Availability: https://machinelearningknowledge.ai/hyperparameter-tuning-with-sklearn-gridsearchcv-and-randomizedsearchcv/[6]\n",
        "#   *\n",
        "#***************************************************************************************/\n",
        "k_range = list(range(1, 31))\n",
        "param_grid = dict(n_neighbors=k_range)\n",
        "grid_knn = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', return_train_score=False)\n",
        "grid_knn.fit(X_train_sc,y_train)\n",
        "print(\"tuned hyperparameters : \",grid_knn.best_params_)\n",
        "print(\"accuracy :\",grid_knn.best_score_*100)"
      ],
      "metadata": {
        "id": "Kxu910RiFNWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on test data \n",
        "grid_predictions = grid_knn.predict(X_test_sc) \n",
        "test_accuracy=accuracy_score(y_test,grid_predictions)*100\n",
        "print(\"Accuracy for our testing dataset with tuning is : {:.2f}%\".format(test_accuracy) )\n",
        "acc6_knn = accuracy_score(y_test, grid_predictions)*100\n",
        "t6_knn =time()\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test,  grid_predictions))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test, grid_predictions))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test,  grid_predictions),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test,  grid_predictions),2))\n",
        "cv = RepeatedKFold(n_splits=10)\n",
        "k_score6 = cross_val_score(knn, X, y, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score6), np.std(k_score6)*2))"
      ],
      "metadata": {
        "id": "wPwlqKNFFeHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison of KNN"
      ],
      "metadata": {
        "id": "bSk9-4P_m9wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The results for KNN are  :                          time = {} ,   Accuracy = {} .\".format(t1_knn, acc1_knn))\n",
        "print(\"The results for KNN using standard scaling are  :   time = {} ,   Accuracy = {} .\".format(t2_knn, acc2_knn))\n",
        "print(\"The results for KNN using PCA are  :                time = {}  ,   Accuracy = {} .\".format(t3_knn, acc3_knn))\n",
        "print(\"The results for KNN using Min_Max Scaling are  :    time = {} ,   Accuracy = {} .\".format(t4_knn, acc4_knn))\n",
        "print(\"The results for KNN using PCA_Min_Max are  :        time = {} ,   Accuracy = {} .\".format(t5_knn, acc5_knn))\n",
        "print(\"The results for KNN using GridSearchCV are  :       time = {} ,   Accuracy = {} .\".format(t6_knn, acc6_knn))"
      ],
      "metadata": {
        "id": "6KRckoMLm-6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison of cross validation scores"
      ],
      "metadata": {
        "id": "2VMvxuHXRPJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross validation score KNN are  :                          {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score1), np.std(k_score1)*2))\n",
        "print(\"Cross validation score KNN using standard scaling are  :   {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score2), np.std(k_score2)*2))\n",
        "print(\"Cross validation score KNN using PCA are  :                {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score3), np.std(k_score3)*2))\n",
        "print(\"Cross validation score KNN using Min_Max Scaling are  :    {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score4), np.std(k_score4)*2))\n",
        "print(\"Cross validation score KNN using PCA_Min_Max are  :        {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score5), np.std(k_score5)*2))\n",
        "print(\"The results for KNN using GridSearchCV are  :              {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score6), np.std(k_score6)*2))"
      ],
      "metadata": {
        "id": "4kj-SLNeRV1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting of KNN[11]\n"
      ],
      "metadata": {
        "id": "zJG9N-tuXc7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import neighbors\n",
        "\n",
        "n_neighbors = 10\n",
        "\n",
        "# we only take the first two features. We could avoid this ugly\n",
        "# slicing by using a two-dim dataset\n",
        "X = data.data[:, :2]\n",
        "y = data.target\n",
        "\n",
        "h = 0.02  # step size in the mesh\n",
        "\n",
        "# Create color maps\n",
        "cmap_light = ListedColormap([\"orange\", \"cyan\", \"cornflowerblue\"])\n",
        "cmap_bold = [\"darkorange\", \"c\", \"darkblue\"]\n",
        "\n",
        "for weights in [\"uniform\", \"distance\"]:\n",
        "    # we create an instance of Neighbours Classifier and fit the data.\n",
        "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
        "    clf.fit(X, y)\n",
        "    \n",
        "    \n",
        "\n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # Put the result into a color plot\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.contourf(xx, yy, Z, cmap=cmap_light)\n",
        "\n",
        "    # Plot also the training points\n",
        "    sns.scatterplot(\n",
        "        x=X[:, 0],\n",
        "        y=X[:, 1],\n",
        "        hue=data.target_names[y],\n",
        "        # palette=cmap_bold,\n",
        "        alpha=1.0\n",
        "        \n",
        "    )\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    plt.title(\n",
        "        \"2-Class classification (k = %i, weights = '%s')\" % (n_neighbors, weights)\n",
        "    )\n",
        "    plt.xlabel(data.feature_names[0])\n",
        "    plt.ylabel(data.feature_names[1])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MQ7JaS73UHqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Decision Tree**[12]\n",
        "Note: Decision tree is invariant to feature scaling.\n",
        "\n",
        "Note : Best accuracy - Decision Tree with (criterion=\"entropy\",random_state=42, splitter=\"random\",max_depth=8)\n",
        "\n",
        "DecisionTree for hyperparameters[13]\n",
        "\n"
      ],
      "metadata": {
        "id": "R1BpRnUNnXqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree with criterion=\"gini\""
      ],
      "metadata": {
        "id": "j0flzTzxqPkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier(criterion=\"gini\",random_state = 42)\n",
        "tree.fit(X_train, y_train)\n",
        "predictions_tree = tree.predict(X_test)\n",
        "acc1_dt = accuracy_score(y_test, predictions_tree)*100\n",
        "t1_dt = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_tree))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_tree))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_tree),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_tree),2))\n",
        "y_pred_proba_tr_1 = tree.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_tr_1),2))\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "dt_score1 = cross_val_score(tree, X, y, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(dt_score1), np.std(dt_score1)*2))"
      ],
      "metadata": {
        "id": "w_iyltgznlHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree with criterion=\"entropy\""
      ],
      "metadata": {
        "id": "ApEffjclp1iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier(criterion=\"entropy\",random_state = 42)\n",
        "tree.fit(X_train, y_train)\n",
        "predictions_tree = tree.predict(X_test)\n",
        "acc2_dt = accuracy_score(y_test, predictions_tree)*100\n",
        "t2_dt = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_tree))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_tree))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_tree),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_tree),2))\n",
        "y_pred_proba_tr_2 = tree.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_tr_2),2))\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "dt_score2 = cross_val_score(tree, X, y, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(dt_score2), np.std(dt_score2)*2))"
      ],
      "metadata": {
        "id": "YwvVeJzZp6H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree with (criterion=\"entropy\",random_state=42, splitter=\"random\",max_depth=8)"
      ],
      "metadata": {
        "id": "6GIUlR_drSRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier(criterion=\"entropy\",random_state=42, splitter=\"random\",max_depth=8)\n",
        "tree.fit(X_train, y_train)\n",
        "predictions_tree = tree.predict(X_test)\n",
        "t3_dt = time()\n",
        "acc3_dt = accuracy_score(y_test, predictions_tree)*100\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_tree))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_tree))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_tree),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_tree),2))\n",
        "y_pred_proba_tr_3 = tree.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_tr_3),2))\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "dt_score3 = cross_val_score(tree, X, y, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(dt_score3), np.std(dt_score3)*2))"
      ],
      "metadata": {
        "id": "aWntcWoQqnN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison of Decision Tree"
      ],
      "metadata": {
        "id": "1K-4jUTxsHC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The results for Decision Tree(criterion=gini) are  :          time = {} ,   Accuracy = {} .\".format(t1_dt, acc1_dt))\n",
        "print(\"The results for Decision Tree(criterion=entropy) are  :       time = {} ,  Accuracy = {} .\".format(t2_dt, acc2_dt))\n",
        "print(\"The results for Decision Tree using other patameters are  :   time = {} ,  Accuracy = {} .\".format(t3_dt, acc3_dt))"
      ],
      "metadata": {
        "id": "pDb74XS7r7eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison of cross validation scores"
      ],
      "metadata": {
        "id": "yFwqzjeQRrKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross validation score Decision Tree(criterion=gini) are  :          {0:.2%} (+/- {1:.2%})\".format(np.mean(dt_score1), np.std(dt_score1)*2))\n",
        "print(\"Cross validation score Decision Tree(criterion=entropy) are  :       {0:.2%} (+/- {1:.2%})\".format(np.mean(dt_score2), np.std(dt_score2)*2))\n",
        "print(\"Cross validation score Decision Tree using other patameters are  :   {0:.2%} (+/- {1:.2%})\".format(np.mean(dt_score3), np.std(dt_score3)*2))"
      ],
      "metadata": {
        "id": "sb-a7FejRvJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Random Forest**[14][15]\n",
        "\n",
        "\n",
        "\n",
        "* Note: best accuracy : RandomForestClassifier(n_estimators = 7, criterion = 'entropy',max_features=15, random_state =42)\n",
        "\n"
      ],
      "metadata": {
        "id": "MKt8e_24tdJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_rf = RandomForestClassifier(n_estimators = 7, criterion = 'entropy',max_features=15, random_state =42)\n",
        "classifier_rf.fit(X_train, y_train)\n",
        "predictions_rf = classifier_rf.predict(X_test)\n",
        "acc1_rf = accuracy_score(y_test, predictions_rf)*100\n",
        "t1_rf = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_rf))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_rf))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_rf),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_rf),2))\n",
        "y_pred_proba_rf_1 = classifier_rf.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_rf_1),2))\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "rf_score1 = cross_val_score(classifier_rf, X, y, cv=10, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(rf_score1), np.std(rf_score1)*2))"
      ],
      "metadata": {
        "id": "ynEAWDo9tVZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of Random Forest"
      ],
      "metadata": {
        "id": "dR4bMD-aJMpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The results for Random Forest are  :                          time = {} ,  Accuracy = {} .\".format(t1_rf, acc1_rf))"
      ],
      "metadata": {
        "id": "-C4698IHwPlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison of cross validation scores"
      ],
      "metadata": {
        "id": "Dbfo0NLml7fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross validation score Random Forest are  :      {0:.2%} (+/- {1:.2%})\".format(np.mean(rf_score1), np.std(rf_score1)*2))"
      ],
      "metadata": {
        "id": "IfLTzz8GR8R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Naive Bayes Classifier**[16][17][18]\n"
      ],
      "metadata": {
        "id": "M2sNVqWoRm0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_nb = GaussianNB()\n",
        "classifier_nb.fit(X_train, y_train)\n",
        "predictions_nb = classifier_nb.predict(X_test)\n",
        "acc1_nb = accuracy_score(y_test,predictions_nb)*100\n",
        "t1_nb = time()\n",
        "\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predictions_nb))\n",
        "print('\\nClassification Report: \\n', classification_report(y_test,predictions_nb))\n",
        "print('Balance Accuracy: ', round(balanced_accuracy_score(y_test, predictions_nb),2))\n",
        "print(\"Accuracy : \", round(metrics.accuracy_score(y_test, predictions_nb),2))\n",
        "y_pred_proba_nb_1 = classifier_nb.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC AUC :\", round(roc_auc_score(y_test, y_pred_proba_nb_1),2))\n",
        "\n",
        "cv = RepeatedKFold(n_splits=10, random_state=1)\n",
        "nb_score1 = cross_val_score(classifier_nb, X, y, cv=10, scoring=\"accuracy\")\n",
        "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(nb_score1), np.std(nb_score1)*2))"
      ],
      "metadata": {
        "id": "FI98XJQEwvpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison of Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "jaqMTukdzg1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The results for Naive Bayes are  :                          time = {} ,  Accuracy = {} .\".format(t1_nb, acc1_nb))"
      ],
      "metadata": {
        "id": "liTqE50ZzhwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison of cross validation score"
      ],
      "metadata": {
        "id": "-1V77ch4n8te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross validation score Naive Bayes are  :        {0:.2%} (+/- {1:.2%})\".format(np.mean(nb_score1), np.std(nb_score1)*2))"
      ],
      "metadata": {
        "id": "palmiFFeSKC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting ROC Curve for all methods in one plot\n"
      ],
      "metadata": {
        "id": "rCCLeBnuzxwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will determine the BIC Scores using the Gaussian Mixture Model\n",
        "# This code was modified from the sample code at the following source \n",
        "#/***************************************************************************************\n",
        "#   *    Title: Compare multiple ROC curves in a single plot\n",
        "#   *    Author: Data School\n",
        "#   *    Date: July 20, 2021\n",
        "#   *    Availability: https://www.youtube.com/watch?v=Vc-qn5VcJmw[19]\n",
        "#   *\n",
        "#***************************************************************************************/\n",
        "from sklearn.svm import SVC\n",
        "lr = LogisticRegression()\n",
        "knn = KNeighborsClassifier()\n",
        "dt = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "svm_new1 = svm.SVC()\n",
        "nb = GaussianNB()\n",
        "\n",
        "lr.fit(X_train, y_train);\n",
        "knn.fit(X_train, y_train);\n",
        "svm_new1.fit(X_train, y_train);\n",
        "dt.fit(X_train, y_train);\n",
        "rf.fit(X_train, y_train);\n",
        "nb.fit(X_train, y_train);\n",
        "\n",
        "disp = plot_roc_curve(lr,X_test, y_test)\n",
        "plot_roc_curve(dt,X_test, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(rf,X_test, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(knn,X_test, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(svm_new1,X_test, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(nb,X_test, y_test, ax=disp.ax_);"
      ],
      "metadata": {
        "id": "ZLRL1mex0CXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting ROC Curve for all methods using PCA"
      ],
      "metadata": {
        "id": "GKFTP0JV0mUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "lr = LogisticRegression()\n",
        "knn = KNeighborsClassifier()\n",
        "dt = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "svm_new2 = svm.SVC()\n",
        "nb = GaussianNB()\n",
        "\n",
        "lr.fit(df_train_pca, y_train);\n",
        "knn.fit(df_train_pca, y_train);\n",
        "svm_new2.fit(df_train_pca, y_train);\n",
        "dt.fit(df_train_pca, y_train);\n",
        "rf.fit(df_train_pca, y_train);\n",
        "nb.fit(df_train_pca, y_train);\n",
        "\n",
        "disp = plot_roc_curve(lr,df_test_pca, y_test)\n",
        "plot_roc_curve(dt,df_test_pca, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(rf,df_test_pca, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(knn,df_test_pca, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(svm_new2,df_test_pca, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(nb,df_test_pca, y_test, ax=disp.ax_);"
      ],
      "metadata": {
        "id": "_jProXoKyb24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting ROC Curve for all methods using standard scaling"
      ],
      "metadata": {
        "id": "RQExt4xs1T6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "lr = LogisticRegression()\n",
        "knn = KNeighborsClassifier()\n",
        "dt = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "svm_new3 = svm.SVC()\n",
        "nb = GaussianNB()\n",
        "\n",
        "lr.fit(X_train_sc, y_train);\n",
        "knn.fit(X_train_sc, y_train);\n",
        "svm_new3.fit(X_train_sc, y_train);\n",
        "dt.fit(X_train_sc, y_train);\n",
        "rf.fit(X_train_sc, y_train);\n",
        "nb.fit(X_train_sc, y_train);\n",
        "\n",
        "disp = plot_roc_curve(lr,X_test_sc, y_test)\n",
        "plot_roc_curve(dt,X_test_sc, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(rf,X_test_sc, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(knn,X_test_sc, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(svm_new3,X_test_sc, y_test, ax=disp.ax_);\n",
        "plot_roc_curve(nb,X_test_sc, y_test, ax=disp.ax_);"
      ],
      "metadata": {
        "id": "9vVTGJCw0wn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Comparing all methods**"
      ],
      "metadata": {
        "id": "913JzBMf3TJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"***********Logistic Regression***********\")\n",
        "print(\"The results for Logistic Regression are  :                      time = {} ,   Accuracy = {} .\".format(t1_lr, acc1_lr))\n",
        "print(\"The results for Logistic Regression using PCA are  :            time = {} ,  Accuracy = {} .\".format(t2_lr, acc2_lr))\n",
        "print(\"The results for Logistic Regression using scaling are  :        time = {} ,  Accuracy = {} .\".format(t3_lr, acc3_lr))\n",
        "print(\"The results for Logistic Regression using Min_max Scaler are  : time = {} ,   Accuracy = {} .\".format(t4_lr, acc4_lr))\n",
        "print(\"The results for Logistic Regression using PCA Min_max  are  :   time = {} ,   Accuracy = {} .\".format(t5_lr, acc5_lr))\n",
        "print(\"\\nThe results for Logistic Regression using GridSearchCV are  :   time = {} ,  Accuracy = {} .\".format(t6_lr, acc6_lr))\n",
        "print(\"\\n***********SVM(Kernel = linear)***********\")\n",
        "print(\"The results for SVM are  :                                      time = {} ,  Accuracy = {} .\".format(t1_svm, acc1_svm))\n",
        "print(\"The results for SVM changing C & gamma  :                       time = {} ,  Accuracy = {} .\".format(t2_svm, acc2_svm))\n",
        "print(\"The results for SVM using PCA are  :                            time = {} ,  Accuracy = {} .\".format(t3_svm, acc3_svm))\n",
        "print(\"The results for SVM using standard scaling are  :               time = {} ,  Accuracy = {} .\".format(t4_svm, acc4_svm))\n",
        "print(\"The results for SVM using Min_Max Scaling are  :                time = {} ,  Accuracy = {} .\".format(t5_svm, acc5_svm))\n",
        "print(\"The results for SVM using PCA Min_Max are  :                    time = {} ,    Accuracy = {} .\".format(t6_svm, acc6_svm))\n",
        "print(\"\\n***********SVM(Kernel = rbf)***********\")\n",
        "print(\"The results for SVM are  :                                      time = {} ,  Accuracy = {} .\".format(t7_svm, acc7_svm))\n",
        "print(\"The results for SVM changing C & gamma  :                       time = {}  ,   Accuracy = {} .\".format(t8_svm, acc8_svm))\n",
        "print(\"The results for SVM using PCA are  :                            time = {} ,  Accuracy = {} .\".format(t9_svm, acc9_svm))\n",
        "print(\"The results for SVM using standard scaling are  :               time = {} ,  Accuracy = {} .\".format(t10_svm, acc10_svm))\n",
        "print(\"The results for SVM using Min_Max Scaling are  :                time = {} ,  Accuracy = {} .\".format(t11_svm, acc11_svm))\n",
        "print(\"The results for SVM using PCA Min_Max are  :                    time = {} ,  Accuracy = {} .\".format(t12_svm, acc12_svm))\n",
        "print(\"\\nThe results for SVM using GridSearchCV are  :                   time = {} ,  Accuracy = {} .\".format(t13_svm, acc13_svm))\n",
        "print(\"\\n***********KNN***********\")\n",
        "print(\"The results for KNN are  :                                      time = {} ,   Accuracy = {} .\".format(t1_knn, acc1_knn))\n",
        "print(\"The results for KNN using standard scaling are  :               time = {} ,   Accuracy = {} .\".format(t2_knn, acc2_knn))\n",
        "print(\"The results for KNN using PCA are  :                            time = {}  ,   Accuracy = {} .\".format(t3_knn, acc3_knn))\n",
        "print(\"The results for KNN using Min_Max Scaling are  :                time = {}  ,  Accuracy = {} .\".format(t4_knn, acc4_knn))\n",
        "print(\"The results for KNN using PCA_Min_Max are  :                    time = {}  ,  Accuracy = {} .\".format(t5_knn, acc5_knn))\n",
        "print(\"The results for KNN using GridSearchCV are  :                   time = {} ,  Accuracy = {} .\".format(t6_knn, acc6_knn))\n",
        "print(\"\\n***********Decision Tree***********\")\n",
        "print(\"The results for Decision Tree(criterion=gini) are  :            time = {} ,   Accuracy = {} .\".format(t1_dt, acc1_dt))\n",
        "print(\"The results for Decision Tree(criterion=entropy) are  :         time = {} ,   Accuracy = {} .\".format(t2_dt, acc2_dt))\n",
        "print(\"The results for Decision Tree using other patameters are  :     time = {} ,   Accuracy = {} .\".format(t3_dt, acc3_dt))\n",
        "print(\"\\n***********Random Forest***********\")\n",
        "print(\"The results for Random Forest are  :                            time = {} ,   Accuracy = {} .\".format(t1_rf, acc1_rf))\n",
        "print(\"\\n***********Naive Bayes***********\")\n",
        "print(\"The results for Naive Bayes are  :                              time = {} ,   Accuracy = {} .\".format(t1_nb, acc1_nb))"
      ],
      "metadata": {
        "id": "iy6RORYY0fUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparing all Cross Validation Scores**"
      ],
      "metadata": {
        "id": "UGqJaNPjnHmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"***********Logistic Regression***********\")\n",
        "print(\"Cross validation score Logistic Regression :                      {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score1), np.std(logisticRegr_score1)*2))\n",
        "print(\"Cross validation score Logistic Regression using PCA:             {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score2), np.std(logisticRegr_score2)*2))\n",
        "print(\"Cross validation score Logistic Regression using scaling:         {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score3), np.std(logisticRegr_score3)*2))\n",
        "print(\"Cross validation score Logistic Regression using Min_max Scaler:  {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score4), np.std(logisticRegr_score4)*2))\n",
        "print(\"Cross validation score Logistic Regression using PCA Min_max:     {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score5), np.std(logisticRegr_score5)*2))\n",
        "print(\"\\nCross validation score Logistic Regression using GridSearchCV:    {0:.2%} (+/- {1:.2%})\".format(np.mean(logisticRegr_score6), np.std(logisticRegr_score6)*2))\n",
        "print(\"\\n***********SVM(Kernel = linear)***********\")\n",
        "print(\"Cross validation score SVM are  :                                 {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score1), np.std(svm_score1)*2))\n",
        "print(\"Cross validation score changing C & gamma  :                      {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score2), np.std(svm_score2)*2))\n",
        "print(\"Cross validation score SVM using PCA are  :                       {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score3), np.std(svm_score3)*2))\n",
        "print(\"Cross validation score SVM using standard scaling are  :          {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score4), np.std(svm_score4)*2))\n",
        "print(\"Cross validation score SVM using Min_Max Scaling are  :           {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score5), np.std(svm_score5)*2))\n",
        "print(\"Cross validation score SVM using PCA Min_Max are  :               {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score6), np.std(svm_score6)*2))\n",
        "print(\"\\n***********SVM(Kernel = rbf)***********\")\n",
        "print(\"Cross validation score SVM are  :                                 {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score7), np.std(svm_score7)*2))\n",
        "print(\"Cross validation score SVM changing C & gamma  :                  {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score8), np.std(svm_score8)*2))\n",
        "print(\"Cross validation score SVM using PCA are  :                       {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score9), np.std(svm_score9)*2))\n",
        "print(\"Cross validation score SVM using standard scaling are  :          {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score10), np.std(svm_score10)*2))\n",
        "print(\"Cross validation score SVM using Min_Max Scaling are  :           {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score11), np.std(svm_score11)*2))\n",
        "print(\"Cross validation score SVM using PCA Min_Max are  :               {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score12), np.std(svm_score12)*2))\n",
        "print(\"\\nCross validation score SVM using GridSearchCV are  :              {0:.2%} (+/- {1:.2%})\".format(np.mean(svm_score13), np.std(svm_score13)*2))\n",
        "print(\"\\n***********KNN***********\")\n",
        "print(\"Cross validation score KNN are  :                                 {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score1), np.std(k_score1)*2))\n",
        "print(\"Cross validation score KNN using standard scaling are  :          {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score2), np.std(k_score2)*2))\n",
        "print(\"Cross validation score KNN using PCA are  :                       {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score3), np.std(k_score3)*2))\n",
        "print(\"Cross validation score KNN using Min_Max Scaling are  :           {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score4), np.std(k_score4)*2))\n",
        "print(\"Cross validation score KNN using PCA_Min_Max are  :               {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score5), np.std(k_score5)*2))\n",
        "print(\"The results for KNN using GridSearchCV are  :                     {0:.2%} (+/- {1:.2%})\".format(np.mean(k_score6), np.std(k_score6)*2))\n",
        "print(\"\\n***********Decision Tree***********\")\n",
        "print(\"Cross validation score Decision Tree(criterion=gini) are  :       {0:.2%} (+/- {1:.2%})\".format(np.mean(dt_score1), np.std(dt_score1)*2))\n",
        "print(\"Cross validation score Decision Tree(criterion=entropy) are  :    {0:.2%} (+/- {1:.2%})\".format(np.mean(dt_score2), np.std(dt_score2)*2))\n",
        "print(\"Cross validation score Decision Tree using other patameters are  :{0:.2%} (+/- {1:.2%})\".format(np.mean(dt_score3), np.std(dt_score3)*2))\n",
        "print(\"\\n***********Random Forest***********\")\n",
        "print(\"Cross validation score Random Forest are  :                        {0:.2%} (+/- {1:.2%})\".format(np.mean(rf_score1), np.std(rf_score1)*2))\n",
        "print(\"\\n***********Naive Bayes***********\")\n",
        "print(\"Cross validation score Naive Bayes are  :                          {0:.2%} (+/- {1:.2%})\".format(np.mean(nb_score1), np.std(nb_score1)*2))\n"
      ],
      "metadata": {
        "id": "iqbupXb2P3kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**References:**\n"
      ],
      "metadata": {
        "id": "CNDDIbxR7oVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Geeks for Geeks. (2019, Jun 6). Implementing DBSCAN algorithm using Sklearn [Online]. Available: https://www.geeksforgeeks.org/implementing-dbscan-algorithm-using-sklearn/\n",
        "\n",
        "[2] S. Plotka. (2018, Jul. 11). Breast Cancer Classification Using Scikit-Learn and Keras [Online]. Available: https://ermlab.com/en/blog/data-science/breast-cancer-classification-using-scikit-learn-and-keras/\n",
        "\n",
        "[3] Tutorials Point. Classification Algorithms – Logistic Regression [Online]. Available: https://www.tutorialspoint.com/machine_learning_with_python/classification_algorithms_logistic_regression.htm\n",
        "\n",
        "[4] J. Brownlee. (2020, Sep. 14) Hyperparameter Optimization With Random Search and Grid Search [Online]. Available: https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/\n",
        "\n",
        "[5] scikit learn. 1.4. Support Vector Machines [Online]. Available: https://scikit-learn.org/stable/modules/svm.html\n",
        "\n",
        "[6] V. Kumar. (2021, Oct. 5). Hyperparameter Tuning with Sklearn GridSearchCv and RandomizedSearchCv [Online]. Available: https://machinelearningknowledge.ai/hyperparameter-tuning-with-sklearn-gridsearchcv-and-randomizedsearchcv/\n",
        "\n",
        "[7] scikit learn. Plot different SVM classifiers in the iris dataset [Online]. Available: https://scikit-learn.org/0.18/auto_examples/svm/plot_iris.html\n",
        "\n",
        "[8] scikit learn. 3.3 Metrics and scoring: quantifying the quality of predictions [Online]. Available: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "[9] A. Bronshtein. (2017, Apr. 11). A Quick Introduction to K-Nearest Neighbors Algorithm [Online]. Available: https://medium.com/@adi.bronshtein/a-quick-introduction-to-k-nearest-neighbors-algorithm-62214cea29c7\n",
        "\n",
        "[10] O. Harrison. (2018, Sep. 10). Machine Learning Basics with the K-Nearest Neighbors Algorithm [Online]. Available: https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761\n",
        "\n",
        "[11] scikit learn. Nearest Neighbors Classification [Online]. Available: https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html\n",
        "\n",
        "[12] Tutorials Point. Classification Algorithms – Decision Tree [Online]. Available: https://www.tutorialspoint.com/machine_learning_with_python/classification_algorithms_decision_tree.htm\n",
        "\n",
        "[13] M. Mithrakumar. (2019, Nov. 11). How to tuna a Decision Tree [Online]. Available: https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n",
        "\n",
        "[14] Tutorials Point. Classification Algorithms – Random Forest [Online]. Available: https://www.tutorialspoint.com/machine_learning_with_python/classification_algorithms_random_forest.htm\n",
        "\n",
        "[15] S. Saxena. (2020, Mar. 12). A Beginner’s Guide to Random Forest Hyperparameter Tuning [Online]. Available: https://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/\n",
        "\n",
        "[16] scikit learn. 1.9 Naïve Bayes [Online]. Available: https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "\n",
        "[17] Geeks for Geeks. (2022 Feb. 2). Naïve Bayes Classifiers [Online]. Available: https://www.geeksforgeeks.org/naive-bayes-classifiers/\n",
        "\n",
        "[18] Tutorials Point. Classification Algorithms – Naïve Bayes [Online]. Available: https://www.tutorialspoint.com/machine_learning_with_python/classification_algorithms_naive_bayes.htm\n",
        "[19] Data School. (2021, Jul. 20). Compare multiple ROC curves in a single plot [Online]. Available: https://www.youtube.com/watch?v=Vc-qn5VcJmw\n",
        "\n"
      ],
      "metadata": {
        "id": "Aw--Nrxz74q3"
      }
    }
  ]
}